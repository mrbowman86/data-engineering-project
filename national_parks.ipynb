{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5eaa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Python libraries\n",
    "# - pandas: for general-purpose data analysis\n",
    "# - psycopg2: for connecting and querying a PostgreSQL database\n",
    "# - polars: a high-performance DataFrame library used here for efficient CSV manipulation\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import polars as pl  # one additional library not covered in class related to data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a57bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw datasets using two different libraries\n",
    "# - parks_df is loaded with Polars for faster string and column manipulation\n",
    "# - observations_df and species_info_df are loaded with Pandas (standard in the bootcamp)\n",
    "parks_df = pl.read_csv('resources/parks.csv')  # Original parks data (includes \"Bryce Canyon National Park\")\n",
    "observations_df = pd.read_csv('resources/observations.csv')  # Animal sightings per park\n",
    "species_info_df = pd.read_csv('resources/species_info.csv')  # Species category and conservation status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2503f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix naming inconsistency:\n",
    "# Replace all instances of \"Bryce Canyon National Park\" with \"Bryce National Park\" in the 'Park Name' column\n",
    "# This ensures it matches the naming convention used in the observations dataset (important for joining later)\n",
    "parks_df = parks_df.with_columns(\n",
    "    pl.col(\"Park Name\").str.replace_all(\"Bryce Canyon National Park\", \"Bryce National Park\").alias(\"Park Name\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2347cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names to align with other datasets\n",
    "# Rename 'Park Name' -> 'park_name' and 'Park Code' -> 'park_code'\n",
    "# This simplifies merging by ensuring columns have consistent names across DataFrames\n",
    "parks_df = parks_df.rename({\n",
    "    \"Park Name\": \"park_name\",\n",
    "    \"Park Code\": \"park_code\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "656dda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned and standardized parks dataset to a new file called 'parks_updated.csv'\n",
    "# This will be used later when merging or importing into a SQL database\n",
    "parks_df.write_csv(\"resources/parks_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71fcf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the PostgreSQL database you previously created in pgAdmin\n",
    "# This allows you to query data stored in your 'national_park_species_db' from Jupyter\n",
    "conn = psycopg2.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"postgres\",\n",
    "    password = \"postgres\",\n",
    "    dbname = \"national_park_species_db\",\n",
    "    port = 5432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09d6b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cursor object that lets you execute SQL commands from Python\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d572f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute SQL to retrieve all rows from the 'observations' table\n",
    "cur.execute(\"select * from observations\")\n",
    "observations = cur.fetchall()  # Store results as a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32edea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute SQL to retrieve all rows from the 'parks_updated' table\n",
    "cur.execute(\"select * from parks_updated\")\n",
    "parks_updated = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc671e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute SQL to retrieve all rows from the 'species_info' table\n",
    "cur.execute(\"select * from species_info\")\n",
    "species_info = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db91ffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations (first 3 rows): [('Vicia benghalensis', 'Great Smoky Mountains National Park', 68), ('Neovison vison', 'Great Smoky Mountains National Park', 77), ('Prunus subcordata', 'Yosemite National Park', 138)]\n",
      "Parks Updated (first 3 rows): [('ACAD', 'Acadia National Park', 'ME', 47390, 44.35, -68.21), ('ARCH', 'Arches National Park', 'UT', 76519, 38.68, -109.57), ('BADL', 'Badlands National Park', 'SD', 242756, 43.75, -102.5)]\n",
      "Species Info (first 3 rows): [('Mammal', 'Clethrionomys gapperi gapperi', \"Gapper's Red-Backed Vole\", None), ('Mammal', 'Bos bison', 'American Bison, Bison', None), ('Mammal', 'Bos taurus', 'Aurochs, Aurochs, Domestic Cattle (Feral), Domesticated Cattle', None)]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 3 rows of each table to visually inspect and confirm data was pulled successfully\n",
    "print(\"Observations (first 3 rows):\", observations[:3])\n",
    "print(\"Parks Updated (first 3 rows):\", parks_updated[:3])\n",
    "print(\"Species Info (first 3 rows):\", species_info[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f57a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform LEFT JOINs using SQL directly from Python:\n",
    "# 1. Join 'observations' with 'parks_updated' on 'park_name'\n",
    "# 2. Then join that result with 'species_info' on 'scientific_name'\n",
    "# This creates one unified dataset containing species observations + park details + species metadata\n",
    "query = \"\"\"\n",
    "    SELECT o.*, \n",
    "           p.park_code, p.State, p.Acres, p.Latitude, p.Longitude,\n",
    "           s.category, s.common_names, s.conservation_status\n",
    "    FROM observations o\n",
    "    LEFT JOIN parks_updated p ON o.park_name = p.park_name\n",
    "    LEFT JOIN species_info s ON o.scientific_name = s.scientific_name\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "final_joined_data = cur.fetchall()  # Store the final joined result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0bf6083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Vicia benghalensis', 'Great Smoky Mountains National Park', 68, 'GRSM', 'TN, NC', 521490, 35.68, -83.53, 'Vascular Plant', 'Purple Vetch, Reddish Tufted Vetch', None)\n",
      "('Neovison vison', 'Great Smoky Mountains National Park', 77, 'GRSM', 'TN, NC', 521490, 35.68, -83.53, 'Mammal', 'American Mink', None)\n",
      "('Prunus subcordata', 'Yosemite National Park', 138, 'YOSE', 'CA', 761266, 37.83, -119.5, 'Vascular Plant', 'Klamath Plum', None)\n"
     ]
    }
   ],
   "source": [
    "# Preview a few rows from the final joined dataset to validate merge success\n",
    "for row in final_joined_data[:3]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "052590a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column headers that match the SQL SELECT statement above\n",
    "# This will be used to create a DataFrame with proper column names\n",
    "original_columns = [\n",
    "    'scientific_name', 'park_name', 'observations',\n",
    "    'park_code', 'State', 'Acres', 'Latitude', 'Longitude',\n",
    "    'category', 'common_names', 'conservation_status'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c029b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of tuples into a Pandas DataFrame using the defined column names\n",
    "df = pd.DataFrame(final_joined_data, columns=original_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e17bdfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns to improve readability or match project requirements\n",
    "# This groups park information, species details, and observations more logically\n",
    "new_order = [\n",
    "    'park_name', 'park_code', 'State', 'Latitude', 'Longitude', 'Acres',\n",
    "    'category', 'common_names', 'scientific_name', 'observations', 'conservation_status'\n",
    "]\n",
    "\n",
    "df = df[new_order]  # Apply the new column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7446b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final merged dataset to a CSV file in the 'resources' folder\n",
    "# This file can be used for further analysis, visualizations, or project presentations\n",
    "df.to_csv(\"resources/National_Parks_Dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c39326db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection to the PostgreSQL database once all queries are complete\n",
    "# This is a good practice to free up system resources and avoid leaving open connections\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
